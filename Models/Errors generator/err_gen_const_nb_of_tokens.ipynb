{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from string import ascii_lowercase\n",
    "import numpy as np\n",
    "import math\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from pandas import read_csv, DataFrame\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"a\": [[\"a\", \"q\", \"w\", \"s\", \"z\"], 5 * [1 / 5]],\n",
    "    \"b\": [[\"b\", \"v\", \"g\", \"h\", \"n\"], 5 * [1 / 5]],\n",
    "    \"c\": [[\"c\", \"x\", \"d\", \"f\", \"v\"], 5 * [1 / 5]],\n",
    "    \"d\": [[\"d\", \"s\", \"e\", \"r\", \"f\", \"c\", \"x\"], 7 * [1 / 7]],\n",
    "    \"e\": [[\"e\", \"w\", \"r\", \"d\", \"s\", \"3\", \"4\"], 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"f\": [[\"f\", \"d\", \"r\", \"t\", \"g\", \"v\", \"c\"], 7 * [1 / 7]],\n",
    "    \"g\": [[\"g\", \"f\", \"t\", \"y\", \"h\", \"b\", \"v\"], 7 * [1 / 7]],\n",
    "    \"h\": [[\"h\", \"g\", \"y\", \"u\", \"j\", \"n\", \"b\"], 7 * [1 / 7]],\n",
    "    \"i\": [[\"i\", \"u\", \"o\", \"k\", \"j\", \"8\", \"9\"], 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"j\": [[\"j\", \"h\", \"u\", \"i\", \"k\", \"m\", \"n\"], 7 * [1 / 7]],\n",
    "    \"k\": [[\"k\", \"j\", \"i\", \"o\", \"l\", \"m\"], 6 * [1 / 6]],\n",
    "    \"l\": [[\"l\", \"k\", \"o\", \"p\"], 4 * [1 / 4]],\n",
    "    \"m\": [[\"m\", \"n\", \"j\", \"k\"], 4 * [1 / 4]],\n",
    "    \"n\": [[\"n\", \"b\", \"h\", \"j\", \"m\"], 5 * [1 / 5]],\n",
    "    \"o\": [[\"o\", \"i\", \"p\", \"l\", \"k\", \"9\", \"0\"], 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"p\": [[\"p\", \"o\", \"l\", \"0\"], 4 * [1 / 4]],\n",
    "    \"q\": [[\"q\", \"w\", \"a\", \"1\", \"2\"], 3 * [1 / 4] + 2 * [1 / 8]],\n",
    "    \"r\": [[\"r\", \"e\", \"t\", \"f\", \"d\", \"4\", \"5\"], 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"s\": [[\"s\", \"a\", \"w\", \"e\", \"d\", \"x\", \"z\"], 7 * [1 / 7]],\n",
    "    \"t\": [[\"t\", \"r\", \"y\", \"g\", \"f\", \"5\", \"6\"], 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"u\": [list(\"uyijh78\"), 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"v\": [list(\"vcfgb\"), 5 * [1 / 5]],\n",
    "    \"w\": [list(\"wqesa23\"), 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"x\": [list(\"xzsdc\"), 5 * [1 / 5]],\n",
    "    \"y\": [list(\"ytuhg67\"), 5 * [1 / 6] + 2 * [1 / 12]],\n",
    "    \"z\": [list(\"zasx\"), 4 * [1 / 4]],\n",
    "    \"1\": [list(\"1qw2\"), 4 * [1 / 4]],\n",
    "    \"2\": [list(\"23wq1\"), 5 * [1 / 5]],\n",
    "    \"3\": [list(\"34ew2\"), 5 * [1 / 5]],\n",
    "    \"4\": [list(\"45re3\"), 5 * [1 / 5]],\n",
    "    \"5\": [list(\"56tr4\"), 5 * [1 / 5]],\n",
    "    \"6\": [list(\"67yt5\"), 5 * [1 / 5]],\n",
    "    \"7\": [list(\"78uy6\"), 5 * [1 / 5]],\n",
    "    \"8\": [list(\"89iu7\"), 5 * [1 / 5]],\n",
    "    \"9\": [list(\"90oi8\"), 5 * [1 / 5]],\n",
    "    \"0\": [list(\"0po9\"), 4 * [1 / 4]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alfabet = \"qwertyuiopasdfghjklzxcvbnm\"\n",
    "row2 = list(\"qwertyuiop\")\n",
    "row1 = list(\"asdfghjkl\")\n",
    "row0 = list(\"zxcvbnm\")\n",
    "def mapping2(cr1, cr2):\n",
    "    k = dict()\n",
    "    chars = [cr1, cr2]\n",
    "    rows = [row0, row1, row2]\n",
    "    \n",
    "    for cr in chars:\n",
    "        if cr in alfabet:\n",
    "            for i, row in enumerate(rows):\n",
    "                if cr in row:\n",
    "                    k[cr] = (i, row.index(cr))\n",
    "        else:\n",
    "            return [el for el in [cr1, cr2] if el in alfabet]\n",
    "\n",
    "    if k[cr1][0] - k[cr2][0] == 0:\n",
    "        if k[cr1][1] - k[cr2][1] == 0:\n",
    "            return [cr2]\n",
    "        elif k[cr1][1] - k[cr2][1] > 0:\n",
    "            return rows[k[cr1][0]] [k[cr2][1]: k[cr1][1] + 1]\n",
    "        else:\n",
    "            return rows[k[cr1][0]] [k[cr1][1]: k[cr2][1] + 1]\n",
    "    elif k[cr1][0] - k[cr2][0] > 0:\n",
    "        if k[cr1][0] - k[cr2][0] == 0:\n",
    "            return [cr1, cr2]\n",
    "        elif k[cr1][1] - k[cr2][1] > 0:\n",
    "            if k[cr1][1] - k[cr2][1] == 1:\n",
    "                return rows[k[cr1][0]] [k[cr2][1] + 1: k[cr1][1] + 1] + rows[k[cr2][0]] [k[cr2][1]: k[cr1][1]]\n",
    "            else:\n",
    "                return rows[k[cr1][0]] [k[cr2][1] + 2: k[cr1][1] + 1] + rows[1] [k[cr2][1] + 1: k[cr1][1]] + rows[k[cr2][0]] [k[cr2][1]: k[cr1][1] - 1]\n",
    "        else:\n",
    "            return rows[k[cr1][0]] [k[cr1][1]: k[cr2][1] + 1] + rows[k[cr2][0]] [k[cr1][1]: k[cr2][1] + 1]\n",
    "    else:\n",
    "        if k[cr1][1] - k[cr2][1] == 0:\n",
    "            return [cr2, cr1]\n",
    "        elif k[cr1][1] - k[cr2][1] > 0:\n",
    "            return rows[k[cr2][0]] [k[cr2][1]: k[cr1][1] + 1] + rows[k[cr1][0]] [k[cr2][1]: k[cr1][1] + 1]\n",
    "        else:\n",
    "            if k[cr2][0] - k[cr1][0] == 1:\n",
    "                return rows[k[cr2][0]] [k[cr1][1] + 1: k[cr2][1] + 1] + rows[k[cr1][0]] [k[cr1][1]: k[cr2][1]]\n",
    "            else:\n",
    "                return rows[k[cr2][0]] [k[cr1][1] + 2: k[cr2][1] + 1] + rows[1] [k[cr1][1] + 1: k[cr2][1]] + rows[k[cr1][0]] [k[cr1][1]: k[cr2][1] - 1]\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping2(\"a\", \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_char(sentence, position, mapping=mapping):\n",
    "    char = sentence.lower()[position]\n",
    "    if char in mapping:\n",
    "        to_swap = mapping[char]\n",
    "    else:\n",
    "        to_swap = [[char],[1]]\n",
    "    return sentence[: position] + str(np.random.choice(to_swap[0], p=to_swap[1])) + sentence[position + 1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_with_neighbour(sentence, position):\n",
    "    if sentence[position] in \" ,./;'[]\\<>?:{}!@#$% ^&*()\" or sentence[position + 1] in \" ,./;'[]\\<> ?:{}!@#$%^&*()\":\n",
    "        return sentence\n",
    "    return sentence[: position] + sentence[position + 1] + sentence[position] + sentence[position + 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_char(sentence, position):\n",
    "    square = mapping2(sentence.lower()[position], sentence.lower()[position + 1])\n",
    "    length = len(square)\n",
    "    if length == 0:\n",
    "        return sentence\n",
    "    else:\n",
    "        return sentence[: position] + str(np.random.choice(square, p=length * [1 / length])) + sentence[position: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_char(sentence, position):\n",
    "    if sentence[position] in \" ,./;'[]\\<>?:{}!@#$% ^&*()\":\n",
    "        return sentence\n",
    "    if sentence[position] == \" \":\n",
    "        return sentence\n",
    "    if sentence[position] in word_tokenize(sentence):\n",
    "        return sentence\n",
    "    return sentence[: position] + sentence[position + 1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = {\n",
    "    1: swap_char,\n",
    "    2: swap_with_neighbour,\n",
    "    3: add_char,\n",
    "    4: loss_char\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_of_errors_in_sentence(length):\n",
    "    #creating distribution: Benford-like\n",
    "    pre_dist = list(map(lambda x: math.log((x+2) / (x + 1), length) * (1 / (pow(x,3) + 1)), range(length)))\n",
    "    norm_pre_dist = pre_dist / np.linalg.norm(pre_dist, 1)\n",
    "    \n",
    "    #moving most probably value\n",
    "    most = length // 25\n",
    "    a, b = norm_pre_dist[: most + 1], norm_pre_dist[most + 1: ]\n",
    "    distribution = list(reversed(a)) + list(b)\n",
    "    \n",
    "    p = np.random.choice(range(length), p=distribution)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, ToktokTokenizer\n",
    "#wylosuj liczbe z przedziału [0;rang-1] - liczba bledów w wyrazeniu - rozkładem zeta\n",
    "#dla każdej jedności, wylosuj miejsca, dla kazdego miejsca wylosuj zakłócenie\n",
    "#zakłócenia - zamiana litery, zamiana dwóch sasiednich znaków, zgubienie litery, wrzucenie dodatkowej litery\n",
    "\n",
    "def error_generator(sentence):\n",
    "    toktok = ToktokTokenizer()\n",
    "    length = len(sentence)\n",
    "    nb = nb_of_errors_in_sentence(length)\n",
    "    \n",
    "    for i in range(nb):\n",
    "        length = len(sentence) - 1\n",
    "        position = np.random.choice(range(length), p=(length)*[1/(length)])\n",
    "        l = len(toktok.tokenize(sentence))\n",
    "        sentence_old = sentence\n",
    "        nb = np.random.randint(1,5)\n",
    "        sentence = functions[nb](sentence, position)\n",
    "        \n",
    "        if l != len(toktok.tokenize(sentence)):\n",
    "            \n",
    "            print(sentence_old)\n",
    "            print(nb, position)\n",
    "            print(sentence)\n",
    "            print()\n",
    "            print(toktok.tokenize(sentence_old))\n",
    "            print(toktok.tokenize(sentence))\n",
    "            print()\n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixie(text, sent_tokenizer=True):\n",
    "    misspelled_sentences = []\n",
    "    if sent_tokenizer:\n",
    "        list_of_sentences = sent_tokenize(text)\n",
    "    else:\n",
    "        list_of_sentences = text\n",
    "\n",
    "    misspelled_sentences = Parallel(n_jobs=-1)(delayed(error_generator)(sentence) for sentence in list_of_sentences)\n",
    "    \n",
    "    return misspelled_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_VALID_UTTERANCES = \"../N-grams/valid_utterances1.csv\"\n",
    "valid_utterances = read_csv(PATH_TO_VALID_UTTERANCES)\n",
    "valid_utterances.columns = [\"utt\"]\n",
    "valid_utterances = list(valid_utterances[\"utt\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_utterances = set(valid_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(valid_utterances)):\n",
    "    if valid_utterances[i][-1] not in \"?!.\":\n",
    "        valid_utterances[i] += \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis = pixie(valid_utterances, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = DataFrame(data = [valid_utterances, mis]).T\n",
    "pair.columns = [\"valid\", \"misspelled\"]\n",
    "pair.to_csv(\"valid_wrong_data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#kontrolowac dlugość napisów, ich długość się zmienia\n",
    "# dorobić lepszy model dodawania \"losowego\" znaku ograniczyć do znaków z prostokąta\n",
    "# dokończyć model zamiany znaku\n",
    "# rozpatrzyć to że zaniechuje ostatonią pozycję\n",
    "# ogarnij proble z wielkością znaków"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
